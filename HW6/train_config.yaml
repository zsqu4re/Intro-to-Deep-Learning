autoregressive_training: true
optimizer_name: Adam
optimizer_config: {lr: 0.001}
lr_scheduler_name: ReduceLROnPlateau
lr_scheduler_config: {mode: min, factor: 0.5, patience: 5}
n_epochs: 50
batch_size: 64
